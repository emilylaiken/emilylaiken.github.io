<!doctype html>
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><html lang="en" class="no-js"> <![endif]-->
<html lang="en">

    <head>

        <!-- Basic -->
        <title>Models</title>

        <!-- Define Charset -->
        <meta charset="utf-8">

        <!-- Responsive Metatag -->
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

        <!-- Page Description and Author -->
        <meta name="description" content="CS109 Final Project">
        <meta name="author" content="Shahriyar Ahmed">

        <!-- Bootstrap CSS  -->
        <link rel="stylesheet" href="asset/bootstrap/css/bootstrap.min.css" type="text/css">

        <!-- Font Awesome CSS -->
        <link rel="stylesheet" href="asset/font-awesome/css/font-awesome.min.css" type="text/css">

        <!-- Owl Carousel CSS -->
        <link rel="stylesheet" href="asset/css/owl.carousel.css" type="text/css">
        <link rel="stylesheet" href="asset/css/owl.theme.css" type="text/css">
        <link rel="stylesheet" href="asset/css/owl.transitions.css" type="text/css">
        
        <!-- Css3 Transitions Styles  -->
        <link rel="stylesheet" type="text/css" href="asset/css/animate.css">
        
        <!-- Lightbox CSS -->
        <link rel="stylesheet" type="text/css" href="asset/css/lightbox.css">

        <!-- Sulfur CSS Styles  -->
        <link rel="stylesheet" type="text/css" href="asset/css/style.css">

        <!-- Responsive CSS Style -->
        <link rel="stylesheet" type="text/css" href="asset/css/responsive.css">


        <script src="asset/js/modernizrr.js"></script>

        

    </head>

    <body>
        <header class="clearfix">
        
        
            <!-- Start  Logo & Naviagtion  -->
            <div class="navbar navbar-default navbar-top">
                <div class="container">
                    <div class="navbar-collapse collapse">
                        
                        <!-- Start Navigation List -->
                        <ul class="nav navbar-nav navbar-right">
                            <li>
                                <a href="index.html">Home</a>
                            </li>
                            <li>
                                <a href="index.html#intro">Intro</a>
                            </li>
                            <li>
                                <a href = "index.html#eda" href="#eda">EDA</a>
                            </li>
                            <li>
                                <a href="index.html#imputation">Pre-processing and Imputation</a>
                            </li>
                            <li>
                                <a class="active" href="index.html#models">Models</a>
                            </li>
                            <li>
                                <a href="index.html#conclusion">Conclusions</a>
                            </li>

                        </ul>
                        <!-- End Navigation List -->
                    </div>
                </div>
            </div>
            <!-- End Header Logo & Naviagtion -->
            
        </header>
        
        
        <!-- Start Header Section -->
        <div class="page-header">
            <div class="overlay">
                <div class="container">
                    <div class="row">
                        <div class="col-md-12">
                            <h1>Predictive Models</h1>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- End Header Section -->
        
        
        <!-- Start About Us Section -->
    <br />
    <br />
    <br />
    <br />
      <section id="summary" class="about-section">
        <div class="container">
            <div class="row">
               <div class="col-md-15">
                    <h2>Summary of Modeling Approach and Trajectory</h2>
                    <br />
                   <div class="about-text">
                       <p>We tested each model on three different data sets: a set of basic census predictors (population of MSA, ages distribution of MSA, gender distribution of MSA, and median income of MSA), a set of all census predictors, and a set of all census predictors plus rates of other crimes. 
                        In each case, we found that rates of other crimes were (as one would expect) much more powerful predictors of murder rate than predictors 
                        from the census data. Our base model was a linear regression on only the basic census data predictors, which had a test-set R2 of close to 0, 
                        meaning it has no more predictive power than predicting the average murder rate for each MSA. The same simple linear regression performed slightly
                        better when using all census predictors and significantly better when using all census predictors plus other crime data. A similar pattern was 
                        observed in the other linear regression-style models we tried, including forward selection of predictors from the simple linear regression, a 
                        linear regression on PCA components, LASSO regression, and Ridge regression. We also tried three quite different styles of models: k-NN 
                        regression, a regression tree, and a random forrest of regression trees. Ultimately, our best model overall was LASSO, which scored test R<sup>2</sup>'s of .006 on basic census data, .01 on all census data, and .5 on census data plus crime data other than murders. We were able to improve the R<sup>2</sup> on the set of all census data a bit further, to .012 and then to .017, using linear regression with PCA and k-NN regression, respectively. For a summary of how the performance of models compared, see the figure immediately below. For more details on each model, please scroll down.
                   </div>
                   <img src="asset/images/allmodels.png" class="img-responsive" alt="About images">

               </div>   
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
    <br />


    <section id="linear-regression" class="portfolio-section-1">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/linear.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>Linear Regression</h3>
                    <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>We ran a simple linear regression on each of the three datasets (basic census predictors, all census predictors, and census predictors plus crime data)</p>

                    <h5>Results</h5> 
                    <p>The linear regression performed poorly, with test-set R<sup>2</sup>'s of close to 0 for each of the three datasets.</p>
                    <h5>Observations</h5>
                       <p>As the datasets became progressively larger, the linear regression's R<sup>2</sup> on the training set improved (of course). However, at the same time, the R<sup>2</sup> on the test set got lower (though remained very close to 0). This pattern is depicted at left. It suggests that the linear regression overfit the training data increasingly as more predictors are added. As a result, we decided to try several other linear regression models with methods to avoid overfitting (forward selection of predictors, PCA, LASSO, and Ridge). We considered the simple linear regression on the smallest predictor set (just basic census data) to be our base model (as previously mentioned, this model had a test-set R<sup>2</sup> close to 0).</p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>    
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />

    <section id="polynomial-regression" class="about-section">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/fwdselection.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>Linear Regression with Forward Selection</h3>
                    <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>Building on the earlier linear regression model, we performed forward selection of predictors based on model BIC. We ran the forward selection process seperately for each of the three datasets (basic census data, all census data, and census data plus crime data).</p>

                    <h5>Results</h5> 
                    <p>The forward selection process using only basic predictors chose a dataset with only one predictor (VC01, or MSA population), and had a test-set R<sup>2</sup> of 0. When allowed to use all census data, again only one predictor was used, but this time it was VC35 (marital status); this model had a test-set R<sup>2</sup> of .011. When allowed to use all census data plus crimes, four crime predictors were chosen, and the test-set R<sup>2</sup> was .5. Overall, along with LASSO, forward selection was one of the best models. The coefficients of predictors in each model are depicted at left.</p>
                    <h5>Observations</h5>
                       <p>Clearly, linear regression with forward selection is superior to linear regression with all predictors because having fewer predictors eliminates some multicollinearity and overfitting. It is interesting that, when allowed to use all census predictors, martial status (VC35) became an important predictor. Since rates of other crimes are much more highly correlated with murder rates than census predictors are, it is not surprsing that the forward selection process on the entire dataset chose only crime predictors. </p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>    
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
    
    <section id="linear-regression-pca" class="portfolio-section-1">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/pca.png" class="img-responsive" alt="About images">
                   </div>
               </div>
              <div class="col-md-7">
                    <h3>Linear Regression with PCA</h3>
                    <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>For each dataset, we generated the minimum set of PCA components that explained 90% of the variance. We then ran a linear regression on these components.</p>

                    <h5>Results</h5> 
                    <p>On the set of basic census predictors, the linear regression with PCA peformed poorly, with a test-set R<sup>2</sup> of -.07. However, on the sets of all census predictors and census predictors plus crimes it did well relative to other models, with test-set R<sup>2</sup>'s of .017 and .42, respectively.</p>
                    <h5>Observations</h5> 
                       <p>PCA does the best of all models on the set of all census predictors. The fact that it performs relatively badly on basic census predictors suggests that these basic predictors are just not highly correlated with murder rates. The scatterplot at right depicts how murder rates vary with the value of the first PCA component for the basic census data--visually, it appears that there is not much correlation.</p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>   
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
     <section id="lasso" class="about-section">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/lasso.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>LASSO Regression</h3>
                    <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>We ran a LASSO regression using cross-validation to determine the optimal penalty parameter. </p>

                    <h5>Results</h5> 
                    <p>Overall, LASSO regression was the best of all the models we tested, scoring test-set R<sup>2</sup>'s of .006 (basic census data), .01 (all census data), and .5 (all census and crime data), respectively--see the figure at left for more detail.</p>
                    <h5>Observations</h5>
                       <p>LASSO regression shrunk the coefficients of many predictors in each dataset to 0, which was useful for understanding which predictors are important. In the basic dataset, the important predictors (predictors with non-zero coefficients) included age (VC02-VC09), total population of the MSA (VC01), income (VC45), and year. In the dataset containing all census predictors, 34 different predictors were important. These included census predictors such as VC35 (marital status), VC28 (number speaking a language other than English at home), and VC42 (number of adults with bachelor's degrees). In the final dataset, which also included observations of crimes other than murder, all crime features were important besides larceny-theft, along with many census predictors.</p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>   
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />

    <section id="ridge" class="portfolio-section-1">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/ridge.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>Ridge Regression</h3>
                   <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>We ran a Ridge regression using cross-validation to determine the optimal penalty parameter. </p>

                    <h5>Results</h5> 
                    <p>Ridge regression did not perform quite as well as LASSO, scoring test-set R<sup>2</sup>'s of .002 (basic census data), -.15 (all census data), and .46 (all census and crime data).
                    <h5>Observations</h5>
                       <p>It seems that one of the reason Ridge may not score as well as LASSO on the test sets is that is overfits the data more, as suggested by the larger gaps between scores on training and test sets (as compared with LASSO). This tendency to overfit is also consistent with the fact that Ridge does not shrink coefficients to 0 while LASSO does--our dataset has many predictors, and therefore regressions that use all of them are more likely to overfit. The negative R<sup>2</sup> value on the test set for the dataset with all census predictors is also consistent with overfitting (as seen in earlier models, such as the simple linear regression).</p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>   
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
    
    <section id="tree" class="about-section">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/tree.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>Regression Tree</h3>
                   <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>We built a single regression tree, using cross validation to determine the optimal depth of the tree. The results of the cross-validation procedure for one dataset (all census predictors) are depicted in the figure at left. The optimal tree depth was determined to be 3 on each of the datasets. We didnâ€™t use probabilistic feature dropout nor cross validation to choose the maximum number of features. We opted to keep this model simple given that random forest incorporates these ensemble complexities in a more useful way.</p>

                    <h5>Results</h5> 
                    <p>The single regression tree performed quite poorly compared to the linear regression-based models: the test-set R<sup>2</sup> value for both the census predictor datasets (the basic set and the full set) were below 0. For the dataset with all predictors (census and crime), the single regression tree had a test-set R<sup>2</sup> of .44.
                    <h5>Observations</h5>
                       <p>The single regression tree does not perform well relative to other models on any of the datasets--perhaps, like the simple linear regression, it suffers from the multicollinearity among the many predictors included.</p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>   
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />

    <section id="random-forest" class="portfolio-section-1">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/forest.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>Random Forest</h3>
                   <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>Building on the single regression tree we had already built, we built a random forest of regression trees, using cross validation to determine the optimal ensemble size one each of thre three datasets. In each case, the optimal ensemble size was around 10.</p>

                    <h5>Results</h5> 
                    <p>Like the single regression tree, the random forest performed quite poorly on all datasets except the one including data for crimes besides murder. Again, both the test-set R<sup>2</sup> for both the basic and full set of census predictors was below 0 (though not quite as far below as for the single tree). When all predictors, including crime levels, were used, the test set R<sup>2</sup> was still only .27. 
                    <h5>Observations</h5>
                       <p>Although the random forest performed relatively poorly, it did give us some insight into which predictors are the most important. The feature importances for the random forest using all predictors (census and crime) is depicted at left. Like in linear regression with forward selection of predictors, robbery is by far the most correlated predictor. Among the census predictors, we see that VC35 (marriage status) and VC28 (number speaking a language other than English at home) are among the important predictors. VC35 was also identified as important by linear regression with forward selection, and both VC35 and VC28 were also identified as important by LASSO.
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>    
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
    <br />


    <section id="knn" class="about-section">
        <div class="container">
            <div class="row">
               <div class="col-md-5">
                   <div class="about-img">
                       <img src="asset/images/knn.png" class="img-responsive" alt="About images">
                   </div>
               </div>
               <div class="col-md-7">
                    <h3>k-NN Regression</h3>
                   <br />
                   <div class="about-text">
                    <h5>Process</h5>
                    <p>We ran a k-NN regression using all predictors available in each dataset, using cross-validation to determine the optimal number of neighbors. For the dataset containing only basic census predictors, this meant 80 neighbors, for the one containing all census predictors, it was 89, and for the one containing all census predictors and crimes besides murder, it was only 9.</p>

                    <h5>Results</h5> 
                    <p>The k-NN regression performed the best of all models on the basic census predictors, reaching a test-set R<sup>2</sup> of 0.015. It also performed very well on the dataset with all census predictors, with a test-set R<sup>2</sup> of .012 (though the fact that the test-set R<sup>2</sup> was lower when using more predictors suggests overfitting). Relative to other models, the k-NN regression didn't do as well on the full dataset including both census predictors and crimes other than murder, with a test-set R<sup>2</sup> of only .31. The figure at left depicts the scores of each k-NN model on the respective training and test sets.
                    <h5>Observations</h5>
                       <p>k-NN is overall a useful model, and is one of the few that has some reasonable predictive power over the datasets with only census predictors. It is worth noting that the optimal number of neighbors used is quite high (between 80 and 90) for the two datasets with only census predictors. In contrast, only 9 neighbors are used for the dataset with census and crime predictors, suggesting (once again) that there is a much higher correlation between crime predictors and murder rates than between census predictors and murder rates. </p>
                   </div>
                   <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                    </div>
                   
                   
               </div>     
            </div>
        </div>
    </section>

    <br />
    <br />
    <br />
    <br />
    
        
        
        <!-- Start Footer Section -->
        <section id="footer-section" class="footer-section">
            <div class="container">
                <div class="row">

                    <div class="col-md-3">
                        <div class="subscription">
                                <a href = "index.html#models"> <input type="submit" class="btn btn-primary" value="Back to Home"> </a>
                        </div>
                    </div>

                    
                    
                    <div class="col-md-3">
                        <div class="section-heading-2">
                            <h3 class="section-title">
                                <span>Group Members</span>
                            </h3>
                        </div>
                        
                        <div class="footer-address">
                            <ul>
                                <li class="footer-contact">Emily Aiken</li>
                                <li class="footer-contact">Molly Graepel</li>
                                <li class="footer-contact">Nathan Little</li>
                                <li class="footer-contact">Adriano Navarro</li>
                            </ul>
                        </div>
                    </div><!--/.col-md-3 -->
                    
                    
                    <div class="col-md-3">
                        <div class="section-heading-2">
                            <h3 class="section-title">
                                <span>Class Information</span>
                            </h3>
                        </div>
                        <div class="footer-address">
                            <ul>
                                <li class="footer-contact">CS109A</li>
                                <li class="footer-contact">Fall 2017</li>
                                <li class="footer-contact">Final Project</li>
                            </ul>
                        </div>
                     
                    </div><!--/.col-md-3 -->
                    
                    <div class="col-md-3">
                        <div class="section-heading-2">
                            <h3 class="section-title">
                                <span>Data Sources</span>
                            </h3>
                        </div>
                        
                        <div class="footer-address">
                            <ul>
                                <li class="footer-contact">Crime data: <a href="https://ucr.fbi.gov/">FBI</a>
                                <li class="footer-contact">Census data: <a href=" https:// factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t">American Community Surveys</a>
                            </ul>
                        </div>
                    </div><!--/.col-md-3 -->

                     
                </div><!--/.row -->
            </div><!-- /.container -->
        </section>
        <!-- End Footer Section -->
        
        
        
        
     <!-- Sulfur JS File -->
        <script src="asset/js/jquery-2.1.3.min.js"></script>
        <script src="asset/js/jquery-migrate-1.2.1.min.js"></script>
        <script src="asset/bootstrap/js/bootstrap.min.js"></script>
        <script src="asset/js/owl.carousel.min.js"></script>
        <script src="asset/js/jquery.appear.js"></script>
        <script src="asset/js/jquery.fitvids.js"></script>
        <script src="asset/js/jquery.nicescroll.min.js"></script>
        <script src="asset/js/lightbox.min.js"></script>
        <script src="asset/js/count-to.js"></script>
        <script src="asset/js/styleswitcher.js"></script>
        
        <script src="asset/js/map.js"></script>
        <script src="http://maps.googleapis.com/maps/api/js?sensor=false"></script>
        <script src="asset/js/script.js"></script>
   
        
    
    </body>
</html>